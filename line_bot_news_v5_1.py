# ==============================================================================
# line_bot_v5.py
# æœ€çµ‚æ•´åˆç‰ˆæœ¬
#
# åŠŸèƒ½äº®é»:
# - è¢«å‹•ç›£è½ç¾¤çµ„å°è©±ï¼Œé€é /bot æŒ‡ä»¤è§¸ç™¼ï¼Œå¯¦ç¾ä¸Šä¸‹æ–‡ç†è§£ã€‚
# - æ”¯æ´ç¾¤çµ„å…§ç”¨æˆ¶åç¨±ç²å–èˆ‡å¿«å–ã€‚
# - æ•´åˆäº†ã€Œä¸€æ¬¡æ€§æ–°èæŸ¥è©¢ã€èˆ‡ã€ŒæŒä¹…åŒ–è¨‚é–±ç®¡ç†ã€çš„å®Œæ•´æŒ‡ä»¤ç³»çµ±ã€‚
# - æ‰€æœ‰è€—æ™‚ä»»å‹™ (æ–°èè™•ç†) å‡åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­è™•ç†ã€‚
# - å®šæ™‚æ¨æ’­ä»»å‹™æ¡ç”¨ã€Œä»»å‹™éˆã€æ¨¡å¼åºåˆ—åŒ–åŸ·è¡Œï¼Œä¿è­·å¾Œç«¯ LLM ä¼ºæœå™¨ã€‚
# - Selenium Driver èƒ½å¤ æ™ºæ…§åˆ¤æ–·ä½œæ¥­ç³»çµ±ï¼Œé©æ‡‰ä¸åŒéƒ¨ç½²ç’°å¢ƒã€‚
# ==============================================================================

# --- Python Standard Libraries ---
import os
import platform
import sys
import time
import json
import logging
import hashlib
import hmac
import base64
import re
import atexit
import argparse
from datetime import datetime, timedelta
import urllib.parse

# --- Third-party Libraries ---
import requests
from flask import Flask, request, jsonify
from dotenv import load_dotenv
from apscheduler.schedulers.background import BackgroundScheduler
import feedparser

# --- Newspaper3k for article scraping ---
from newspaper import Article, Config

# --- Selenium for dynamic content scraping ---
from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
# from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import WebDriverException

# (åœ¨æª”æ¡ˆé ‚éƒ¨ï¼Œèˆ‡å…¶ä»– import æ”¾åœ¨ä¸€èµ·)
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==============================================================================
# --- ç’°å¢ƒè¨­å®šã€æ—¥èªŒèˆ‡ Flask åˆå§‹åŒ– ---
# ==============================================================================
load_dotenv()
app = Flask(__name__)

# --- æ—¥èªŒè¨­å®š ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]',
    stream=sys.stdout
)

# --- å…¨åŸŸè®Šæ•¸èˆ‡å¸¸æ•¸ ---
BOT_TRIGGER_WORD = os.getenv("BOT_TRIGGER_WORD", "/bot")
OPENAI_COMPLETION_MODEL = os.getenv("OPENAI_COMPLETION_MODEL", "gpt-4o-mini")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com")
TARGET_USER_ID_FOR_TESTING = os.getenv("TARGET_USER_ID_FOR_TESTING")

VISUAL_SEPARATION_DELAY = float(os.getenv("VISUAL_SEPARATION_DELAY", "1.0"))
DEFAULT_NEWS_KEYWORDS = "å¤§å‹èªè¨€æ¨¡å‹ OR LLM OR ç”Ÿæˆå¼AI OR OpenAI OR Gemini OR Claude"
USER_PREFERENCES_FILE = "user_preferences.json"
CONVERSATION_HISTORY_FILE = "conversation_history.json"
MAX_HISTORY_MESSAGES = int(os.getenv("MAX_HISTORY_MESSAGES", "50"))
NEWS_FETCH_TARGET_COUNT = 7
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'

NEWS_CACHE_FILE = "news_cache.json"
NEWS_SUMMARY_CACHE_SECONDS = 3600 * 4  # 4 å°æ™‚

# --- ç”¨æˆ¶å€‹äººè³‡æ–™å¿«å– (in-memory) ---
USER_PROFILE_CACHE = {}
USER_PROFILE_CACHE_SECONDS = 7200  # å¿«å– 2 å°æ™‚

MAX_MESSAGE_LENGTH = int(os.getenv("MAX_MESSAGE_LENGTH", "4800"))

NEWS_FETCH_MAX_WORKERS=4

# --- å…©éšæ®µæ‘˜è¦çš„ LLM Prompt è¨­å®š ---
PROMPT_FOR_INDIVIDUAL_SUMMARY = (
    "ä½ æ˜¯ä¸€ä½è³‡æ·±çš„æ–°èç·¨è¼¯ï¼Œå°ˆé•·æ˜¯å¿«é€Ÿæç…‰æ–‡ç« æ ¸å¿ƒã€‚è«‹å°‡ä»¥ä¸‹æä¾›çš„æ–°èå…§æ–‡ï¼Œæ¿ƒç¸®æˆä¸€æ®µä¸è¶…é150å­—çš„å®¢è§€ã€ç²¾ç°¡ä¸­æ–‡æ‘˜è¦ã€‚"
    "æ‘˜è¦æ‡‰åŒ…å«æœ€é—œéµçš„äººç‰©ã€äº‹ä»¶ã€æ•¸æ“šå’Œçµè«–ã€‚è«‹ç›´æ¥è¼¸å‡ºæ‘˜è¦å…§å®¹ï¼Œä¸è¦æœ‰ä»»ä½•é–‹é ­æˆ–çµå°¾çš„å®¢å¥—è©±ã€‚"
)

current_date = datetime.now().strftime("%Y-%m-%d %H:%M")
PROMPT_FOR_FINAL_AGGREGATION = (
    f"ä»Šå¤©æ—¥æœŸæ˜¯ {current_date}ã€‚\n"
    "ä½ æ˜¯ä¸€ä½é¢¨è¶£å¹½é»˜ã€çŸ¥è­˜æ·µåšçš„ç§‘æŠ€æ–°è Podcast ä¸»æŒäººã€‚ä½ çš„è½çœ¾æ˜¯ Line ç”¨æˆ¶ï¼Œä»–å€‘å–œæ­¡è¼•é¬†ã€æ˜“æ‡‚ä¸”å¸¶æœ‰ Emoji çš„å…§å®¹ã€‚"
    "æ¥ä¸‹ä¾†æˆ‘æœƒæä¾›æ•¸å‰‡ã€Œå·²ç¶“è¢«ç²¾ç°¡éçš„æ–°èæ‘˜è¦ã€ã€‚è«‹ä½ æ ¹æ“šé€™äº›æ‘˜è¦ï¼Œç™¼æ®ä½ çš„ä¸»æŒé¢¨æ ¼ï¼Œå°‡å®ƒå€‘æ•´åˆæˆä¸€ç¯‡é€£è²«çš„è«‡è©±æ€§å…§å®¹ã€‚"
    "è«‹åªæ•´åˆæœ€æ–°æ–°èæ‘˜è¦ï¼ŒéèˆŠçš„è«‹å¿½ç•¥ã€‚"
    "ä½ çš„ä»»å‹™æ˜¯ï¼š\n"
    "1. ç”¨ç”Ÿå‹•çš„èªæ°£é–‹å ´ï¼Œå¸å¼•è½çœ¾æ³¨æ„ã€‚\n"
    "2. å°‡å„å‰‡æ–°èæ‘˜è¦è‡ªç„¶åœ°ä¸²é€£èµ·ä¾†ï¼Œå¯ä»¥åŠ ä¸Šä½ çš„è©•è«–æˆ–è§€é»ä¾†éŠœæ¥ï¼Œä½†ä¸è¦æœæ’°ä¸å­˜åœ¨çš„äº‹å¯¦ã€‚\n"
    "3. åœ¨æåˆ°æ¯å‰‡æ–°èçš„é‡é»å¾Œï¼Œè«‹å‹™å¿…é™„ä¸Šé€™å‰‡æ–°èçš„åŸå§‹æ¨™é¡Œï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
    "   - æ¨™é¡Œï¼š[åŸå§‹æ–°èæ¨™é¡Œ]\n"
    "4. å…¨ç¨‹å¤šä½¿ç”¨ Emoji ä¾†å¢åŠ æ´»æ½‘æ„Ÿã€‚\n"
    "5. è¦åš´è‚…æ‡‰å°æ¯å‰‡æœ‰è² é¢æƒ…ç·’çš„æ–°èä¾‹å¦‚ç½é›£èˆ‡å‚·äº¡ã€‚\n"
    "6. æœ€å¾Œçµè«–è¦åŠ è¨»é€™æ˜¯AIç”Ÿæˆçš„å…§å®¹ï¼Œè®€è€…æ‡‰æ³¨æ„æ­£ç¢ºæ€§ã€‚\n"
    "7. ç¸½çµçš„å›ç­”å­—æ•¸é™åˆ¶åœ¨500å­—ä»¥ä¸‹ä»¥ç¬¦åˆé€šè¨Šè»Ÿé«”çš„é™åˆ¶ã€‚\n"
)

# --- æ©Ÿå™¨äººæŒ‡ä»¤å¹«åŠ©è¨Šæ¯ ---
HELP_MESSAGE = """
å“ˆå›‰ï¼ğŸ‘‹ æˆ‘æ˜¯ä½ çš„ AI åŠ©ç†ï¼

ä½ å¯ä»¥é€é `/bot` æŒ‡ä»¤èˆ‡æˆ‘äº’å‹•ã€‚

ğŸ“°ã€æ–°èåŠŸèƒ½ã€‘
ğŸ”¹ `/bot æ–°è`
   ç«‹å³å–å¾—ä¸€ç¯‡ AI ä¸»é¡Œçš„æ–°èæ‘˜è¦ã€‚
ğŸ”¹ `/bot æ–°è é—œéµå­—:ä½ æƒ³çœ‹çš„å…§å®¹`
   ç«‹å³æŸ¥è©¢ç‰¹å®šä¸»é¡Œçš„æ–°èã€‚
ğŸ”¹ `/bot è¨‚é–±`
   è¨‚é–±æ¯æ—¥ AI æ–°èæ¨æ’­ã€‚
ğŸ”¹ `/bot è¨‚é–± [ä½ çš„ä¸»é¡Œ]`
   è¨‚é–±æ¯æ—¥ç‰¹å®šä¸»é¡Œçš„æ–°èã€‚
ğŸ”¹ `/bot æŸ¥çœ‹è¨‚é–±`
   çœ‹çœ‹ä½ ç›®å‰è¨‚é–±äº†ä»€éº¼ã€‚
ğŸ”¹ `/bot å–æ¶ˆè¨‚é–±`
   å–æ¶ˆæ¯æ—¥æ–°èæ¨æ’­ã€‚

ğŸ’¬ã€éš¨æ„èŠå¤©ã€‘
é™¤äº†æ–°èï¼Œä¹Ÿå¯ä»¥éš¨æ™‚ç”¨ `/bot` å•æˆ‘ä»»ä½•å•é¡Œå–”ï¼
ç¯„ä¾‹ï¼š`/bot å¹«æˆ‘è¦åŠƒä¸€ä¸‹é€±æœ«è¡Œç¨‹`
"""

# ==============================================================================
# --- æ–°èæ“·å–æ¨¡çµ„ ---
# ==============================================================================
newspaper_config = Config()
newspaper_config.browser_user_agent = USER_AGENT
newspaper_config.request_timeout = 15
newspaper_config.memoize_articles = False

chrome_options = Options()
chrome_options.add_argument("--headless")
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--window-size=1024x400")
chrome_options.add_argument(f"user-agent={USER_AGENT}")

def get_real_url(google_news_url):
    try:
        headers = {"User-Agent": USER_AGENT}
        # ç”¨ GET ä¸”å…è¨±è·³è½‰ï¼›ä¸ä¸‹è¼‰æ•´é å…§å®¹
        with requests.get(google_news_url, headers=headers, allow_redirects=True, timeout=20, stream=True) as r:
            return r.url
    except requests.RequestException as e:
        logging.warning(f"[éŒ¯èª¤] è§£æè·³è½‰é€£çµå¤±æ•— {google_news_url}: {e}")
        return None

def fetch_article_with_selenium(url):
    logging.info(f"    [å‚™æ´] Selenium æŠ“å–: {url[:70]}...")
    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(20)
        driver.get(url)
        time.sleep(2.5)
        return driver.page_source
    except Exception as e:
        logging.error(f"    [Selenium éŒ¯èª¤] {e}", exc_info=True)
        return None
    finally:
        if driver:
            try: driver.quit()
            except Exception: pass

def fetch_and_parse_articles(custom_query=None, limit=NEWS_FETCH_TARGET_COUNT):
    """
    *** å·²å‡ç´š v2ï¼šæ¡ç”¨å¹³è¡ŒåŒ–è™•ç†ä¾†åŠ é€Ÿæ–°èæŠ“å– ***
    """
    query_to_use = custom_query.strip() if custom_query and custom_query.strip() else DEFAULT_NEWS_KEYWORDS
    encoded_query = urllib.parse.quote_plus(query_to_use)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    
    logging.info(f">>> é–‹å§‹å¾ Google News RSS å–å¾—æ–°èåˆ—è¡¨ (é—œéµå­—: '{query_to_use}')")
    feed = feedparser.parse(rss_url)

    if feed.bozo:
        logging.error(f"ç„¡æ³•è§£æ RSS feedã€‚éŒ¯èª¤è³‡è¨Š: {feed.bozo_exception}")
        return []

    # å…§éƒ¨è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼è™•ç†å–®ä¸€æ–‡ç« çš„å®Œæ•´æŠ“å–æµç¨‹
    def _process_single_entry(entry):
        logging.info(f"  [åŸ·è¡Œç·’] é–‹å§‹è™•ç†: {entry.title}")
        real_url = get_real_url(entry.link)
        if not real_url:
            logging.warning(f"  [åŸ·è¡Œç·’] è·³é: ç„¡æ³•å–å¾—çœŸå¯¦ URL for {entry.title}")
            return None
        
        try:
            article = Article(real_url, language='zh', config=newspaper_config)
            article.download()
            article.parse()
            
            if len(article.text) < 200:
                logging.warning(f"  [åŸ·è¡Œç·’] å…§å®¹éçŸ­ï¼Œç‚º {entry.title} å•Ÿç”¨ Seleniumã€‚")
                html_content = fetch_article_with_selenium(real_url)
                if html_content:
                    article.download(input_html=html_content)
                    article.parse()

            if article.title and len(article.text) > 200:
                logging.info(f"  [åŸ·è¡Œç·’] æˆåŠŸå–å¾—: {article.title}")
                return {
                    'title': article.title,
                    'text': article.text,
                    'url': real_url,
                    'source': entry.source.title if hasattr(entry, 'source') and hasattr(entry.source, 'title') else "æœªçŸ¥ä¾†æº"
                }
            else:
                logging.warning(f"  [åŸ·è¡Œç·’] å¤±æ•—: ç„¡æ³•ç‚º {entry.title} è§£æè¶³å¤ å…§æ–‡ã€‚")
                return None
        except Exception as e:
            logging.error(f"  [åŸ·è¡Œç·’] è™•ç† {entry.title} æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return None

    # --- å¹³è¡ŒåŒ–è™•ç†æ ¸å¿ƒ ---
    successful_articles = []
    processed_urls = set()
    
    # æˆ‘å€‘åªè™•ç†å‰ limit * 2 æ•¸é‡çš„æ¢ç›®ï¼Œä»¥é˜²å¾ˆå¤šæ¢ç›®éƒ½å¤±æ•—
    entries_to_process = feed.entries[:limit * 2]
    
    # max_workers å¯ä»¥æ ¹æ“šæ‚¨çš„ä¼ºæœå™¨æ€§èƒ½èª¿æ•´ï¼Œ8 æ˜¯ä¸€å€‹æ¯”è¼ƒåˆç†çš„èµ·å§‹å€¼
    try:
        max_workers = int(os.getenv("NEWS_FETCH_MAX_WORKERS", "4"))
    except ValueError:
        max_workers = 4 # å¦‚æœ .env ä¸­çš„å€¼ä¸æ˜¯æ•¸å­—ï¼Œå‰‡ä½¿ç”¨å®‰å…¨çš„é è¨­å€¼
    
    logging.info(f"å•Ÿå‹• ThreadPoolExecutorï¼Œæœ€å¤§å¹³è¡Œåº¦ (max_workers) è¨­ç‚º: {max_workers}")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_entry = {executor.submit(_process_single_entry, entry): entry for entry in entries_to_process}
        
        for future in as_completed(future_to_entry):
            if len(successful_articles) >= limit:
                # å¦‚æœå·²ç¶“é”åˆ°ç›®æ¨™æ•¸é‡ï¼Œæˆ‘å€‘å¯ä»¥å–æ¶ˆé‚„åœ¨é‹è¡Œçš„æœªä¾†ä»»å‹™
                # é€™è£¡ç‚ºäº†ç°¡å–®èµ·è¦‹ï¼Œæˆ‘å€‘åªè·³å‡ºè¿´åœˆï¼Œè®“å®ƒå€‘ç¹¼çºŒé‹è¡Œå®Œ
                break

            try:
                result = future.result()
                if result and result['url'] not in processed_urls:
                    successful_articles.append(result)
                    processed_urls.add(result['url'])
            except Exception as exc:
                entry_title = future_to_entry[future].title
                logging.error(f"  [ä¸»åŸ·è¡Œç·’] è™•ç† '{entry_title}' çš„ä»»å‹™ç”¢ç”Ÿäº†ç•°å¸¸: {exc}")

    logging.info(f">>> å¹³è¡ŒåŒ–æ–°èå…§æ–‡æ“·å–å®Œæˆï¼Œå…±æˆåŠŸå–å¾— {len(successful_articles)} ç¯‡ã€‚")
    return successful_articles[:limit] # æœ€å¾Œå†è£åˆ‡ä¸€æ¬¡ï¼Œç¢ºä¿æ•¸é‡ä¸è¶…é limit

def _extract_assistant_text_from_response(resp_json: dict) -> str:
    if not resp_json or "choices" not in resp_json or not resp_json["choices"]:
        return ""
    ch0 = resp_json["choices"][0]
    msg = ch0.get("message", {}) or {}

    # 1) content å¯èƒ½æ˜¯å­—ä¸²æˆ– parts
    content = msg.get("content")
    if isinstance(content, str) and content.strip():
        return content.strip()
    if isinstance(content, list):
        parts = []
        for p in content:
            if isinstance(p, str):
                parts.append(p)
            elif isinstance(p, dict):
                txt = p.get("text") or p.get("output_text") or p.get("data") or p.get("value") or ""
                if txt: parts.append(txt)
        if parts:
            return "".join(parts).strip()

    # 2) å…¼å®¹èˆŠçš„ choices[0].text
    legacy = ch0.get("text")
    if isinstance(legacy, str) and legacy.strip():
        return legacy.strip()

    # 3) content ä¸å¯ç”¨ â†’ è©¦è‘—å¾ reasoning_content çš„ Draft æŠ½
    rc = msg.get("reasoning_content")
    draft = _extract_draft_from_reasoning(rc or "")
    if draft:
        return draft

    # 4) æœ€å¾Œæ‰çœ‹ç’°å¢ƒé–‹é—œï¼Œæ˜¯å¦æ•´åŒ…ä¸Ÿå›
    if os.getenv("ALLOW_REASONING_FALLBACK", "false").lower() == "true" and isinstance(rc, str) and rc.strip():
        return rc.strip()

    return ""



import re, json

# å¸¸è¦‹çš„ Draft æ¨™è¨˜æ¨£å¼
_DRAFT_PATTERNS = [
    r'Draft[:ï¼š]\s*[\"â€œ](.+?)[\"â€]\s*$',              # Draft: "...."
    r'Draft[:ï¼š]\s*```(?:\w+)?\n(.+?)\n```',          # Draft: ``` ... ```
    r'###\s*Draft\s*\n(.+)$',                         # Markdown æ¨™é¡Œ Draft
    r'è‰ç¨¿[:ï¼š]\s*(.+)$',                              # ä¸­æ–‡ã€Œè‰ç¨¿:ã€
    r'æœ€çµ‚ç¨¿[:ï¼š]\s*(.+)$',                            # ä¸­æ–‡ã€Œæœ€çµ‚ç¨¿:ã€
]

def _extract_draft_from_reasoning(reasoning: str) -> str:
    if not reasoning:
        return ""
    text = reasoning.strip()

    # 1) å…ˆå˜—è©¦åš´æ ¼çš„ Draft æ¨™è¨˜
    for pat in _DRAFT_PATTERNS:
        m = re.search(pat, text, flags=re.S)
        if m and m.group(1):
            draft = m.group(1).strip()
            # å»æ‰å¾Œé¢å¯èƒ½æ¥çš„ã€Œå­—æ•¸çµ±è¨ˆ/Count:ã€
            draft = re.split(r'\n(?:Count|å­—|characters)[:ï¼š]', draft)[0].strip()
            return draft

    # 2) æœ‰äº›æœƒè¼¸å‡º JSONï¼ŒæŠŠ "summary" æ”¾åœ¨ reasoning è£¡
    jm = re.search(r'\{.*\}', text, flags=re.S)
    if jm:
        try:
            obj = json.loads(jm.group(0))
            for key in ("summary", "final", "output", "answer"):
                if isinstance(obj.get(key, ""), str) and obj[key].strip():
                    return obj[key].strip()
        except Exception:
            pass

    # 3) é€€è€Œæ±‚å…¶æ¬¡ï¼šæŠ“æœ€å¾Œä¸€æ®µçœ‹èµ·ä¾†åƒå®Œæ•´ä¸­æ–‡å¥å­çš„å…§å®¹
    sent = re.findall(r'[\u4e00-\u9fffï¼Œã€ï¼›ï¼šï¼šã€Œã€ã€ã€ï¼ˆï¼‰()A-Za-z0-9%\- ]+[ã€‚.!?]', text)
    if sent:
        return sent[-1].strip()

    return ""

# ==============================================================================
# --- OpenAI & LLM äº’å‹•æ¨¡çµ„ ---
# ==============================================================================
def call_openai_api(messages, model=OPENAI_COMPLETION_MODEL, max_tokens=4000, temperature=0.7):
    if not OPENAI_API_KEY:
        logging.error("OPENAI_API_KEY is not set.")
        return "æŠ±æ­‰ï¼ŒAPI Key æœªè¨­å®šï¼Œç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json", "ngrok-skip-browser-warning": "true"}
    data = {"model": model, "messages": messages, "max_tokens": max_tokens, "temperature": temperature}
    try:
        response = requests.post(f"{OPENAI_BASE_URL}/v1/chat/completions", headers=headers, json=data, timeout=980)
        response.raise_for_status()
        logging.info(response.json())
#         content = response.json()["choices"][0]["message"]["content"].strip()
        resp_json = response.json()
        logging.info(str(resp_json))  # å»ºè­°ä¿ç•™ä»¥ä¾¿é™¤éŒ¯

        content = _extract_assistant_text_from_response(resp_json)
        if (not content or not content.strip()) and os.getenv("ALLOW_REASONING_FALLBACK", "false").lower() == "true":
            content = str(resp_json)
        
        logging.info(f"OpenAI API å‘¼å«æˆåŠŸï¼Œæ¨¡å‹: {model}ï¼Œå›æ‡‰é•·åº¦: {len(content)}")
        return content
    except requests.exceptions.Timeout:
        logging.error(f"OpenAI API request timed out. Model: {model}")
        return f"æŠ±æ­‰ï¼Œè«‹æ±‚ OpenAI ({model}) æœå‹™è¶…æ™‚ã€‚"
    except requests.exceptions.RequestException as e:
        logging.error(f"OpenAI API request error: {e}. Model: {model}")
        return f"æŠ±æ­‰ï¼Œé€£æ¥ OpenAI ({model}) æœå‹™æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"
    except (KeyError, IndexError, TypeError) as e:
        response_text = response.text if 'response' in locals() else 'N/A'
        logging.error(f"OpenAI API response format error: {e} - Response: {response_text}")
        return f"æŠ±æ­‰ï¼ŒOpenAI ({model}) å›æ‡‰æ ¼å¼æœ‰å•é¡Œã€‚"
    except Exception as e:
        logging.error(f"Unexpected error in call_openai_api: {e}", exc_info=True)
        return "æŠ±æ­‰ï¼Œç”Ÿæˆå›è¦†æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ã€‚"

def generate_chat_response(context_id, prompt_text):
    system_prompt = (
        "ä½ æ˜¯ä¸€å€‹åœ¨ Line ç¾¤çµ„æˆ–ç§èŠä¸­çš„èŠå¤©æ©Ÿå™¨äººã€‚ä½ çš„å›ç­”è¦ç²¾ç°¡ã€å£èªåŒ–ï¼Œä½¿ç”¨å°ç£å¸¸ç”¨çš„ç¹é«”ä¸­æ–‡ã€‚"
        "ä½ æœƒæ”¶åˆ°ä¸€æ®µåŒ…å«å¤šäººå°è©±çš„æ­·å²ç´€éŒ„ï¼Œæ¯å¥è©±å‰é¢å¯èƒ½æœƒæ¨™ç¤ºç™¼è¨€è€…ã€‚è«‹å®Œå®Œå…¨å…¨æ ¹æ“šå®Œæ•´çš„ä¸Šä¸‹æ–‡é€²è¡Œå›ç­”ã€‚"
        "è«‹æ ¹æ“šæˆ‘å€‘çš„å°è©±æ­·å²ä¾†å›æ‡‰æ‰€æœ‰å•é¡Œã€‚å¿½ç•¥ä»»ä½•å¤–éƒ¨çŸ¥è­˜æˆ–æ–°ä¸»é¡Œï¼Œä¹Ÿä¸è¦æ ¹æ“šå·²çŸ¥è¨˜æ†¶ï¼Œåªä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡å…§å®¹ç”Ÿæˆç­”æ¡ˆã€‚"
        "å¦‚æœç­”æ¡ˆéœ€è¦æ€è€ƒæ­¥é©Ÿï¼Œè«‹å°‡æ€è€ƒéç¨‹ç”¨ <think> å’Œ </think> æ¨™ç±¤åŒ…èµ·ä¾†ã€‚"
    )
    context_history = CONVERSATION_HISTORY.get(context_id, [])
    messages_for_api = [{"role": "system", "content": system_prompt}] + context_history
    bot_response = call_openai_api(messages_for_api)
    return bot_response

# ==============================================================================
# --- æ–°èæ‘˜è¦èˆ‡æ•´åˆæ¨¡çµ„ ---
# ==============================================================================
def summarize_news_flow(articles_data):
    if not articles_data: return "ä»Šå¤©æ²’æœ‰æŠ“å–åˆ°ç›¸é—œæ–°èå¯ä¾›æ‘˜è¦ã€‚"
    logging.info("--- é–‹å§‹ç¬¬ä¸€éšæ®µæ‘˜è¦ï¼šé€ç¯‡ç²¾ç°¡ ---")
    individual_summaries = []
    for i, article in enumerate(articles_data):
        logging.info(f"  æ­£åœ¨æ‘˜è¦ç¬¬ {i+1}/{len(articles_data)} ç¯‡: {article['title']}")
        content_to_summarize = article['text'][:8000]
        user_prompt = f"æ–°èæ¨™é¡Œï¼š{article['title']}\n\næ–°èå…§æ–‡ï¼š\n{content_to_summarize}"
        raw_summary = call_openai_api([{"role": "system", "content": PROMPT_FOR_INDIVIDUAL_SUMMARY}, {"role": "user", "content": user_prompt}], model=os.getenv("OPENAI_COMPLETION_MODEL", "gpt-4o-mini"), max_tokens=3500, temperature=0.2)
        
        logging.info(f"  user_prompt: {user_prompt}")
        logging.info(f"  raw_summary: {raw_summary}")
        
        if raw_summary.startswith("æŠ±æ­‰ï¼Œ"):
            logging.warning(f"  [è·³é] ç¬¬ {i+1} ç¯‡æ–°èæ‘˜è¦å¤±æ•—: {raw_summary}")
            continue
        think_pattern = re.compile(r"<think>.*?</think>", re.DOTALL | re.IGNORECASE)
        cleaned_summary = re.sub(think_pattern, '', raw_summary).strip()
        if len(raw_summary) != len(cleaned_summary): logging.info(f"  å·²æ¸…ç†æ‰ <think> æ¨™ç±¤ã€‚")
        individual_summaries.append({'title': article['title'], 'url': article['url'], 'summary': cleaned_summary})
        logging.info(f"  æ‘˜è¦å®Œæˆï¼Œé•·åº¦: {len(cleaned_summary)} å­—")
        logging.info(f"  ç­‰å¾…30ç§’ é¿å…LLMé€Ÿç‡é™åˆ¶")
        time.sleep(30) # é™ä½LLMé€Ÿç‡
    if not individual_summaries: return "æŠ±æ­‰ï¼Œä»Šæ—¥æ–°èæ‘˜è¦ç”Ÿæˆéç¨‹ç™¼ç”Ÿå•é¡Œï¼Œç„¡æ³•ç”¢å‡ºå…§å®¹ã€‚"
    logging.info("--- é–‹å§‹ç¬¬äºŒéšæ®µæ‘˜è¦ï¼šå½™æ•´ç”Ÿæˆ Podcast å…§å®¹ ---")
    summaries_for_prompt = [f"æ–°è {i+1}:\næ¨™é¡Œ: {item['title']}\næ‘˜è¦å…§å®¹: {item['summary']}\n---" for i, item in enumerate(individual_summaries)]
    final_user_prompt = "\n".join(summaries_for_prompt)
    final_summary = call_openai_api([{"role": "system", "content": PROMPT_FOR_FINAL_AGGREGATION}, {"role": "user", "content": final_user_prompt}], model=os.getenv("OPENAI_COMPLETION_MODEL", "gpt-4o"), max_tokens=3000, temperature=0.7)
    return final_summary

# ==============================================================================
# --- Line Bot åŸºç¤åŠŸèƒ½èˆ‡è³‡æ–™è™•ç† ---
# ==============================================================================
def load_json_data(file_path):
    try:
        with open(file_path, "r", encoding='utf-8') as f: return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError): return {}

def save_json_data(data, file_path):
    try:
        with open(file_path, "w", encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=4)
    except Exception as e: logging.error(f"å„²å­˜æª”æ¡ˆ {file_path} å¤±æ•—: {e}")

USER_PREFERENCES = load_json_data(USER_PREFERENCES_FILE)
CONVERSATION_HISTORY = load_json_data(CONVERSATION_HISTORY_FILE)
NEWS_CACHE = load_json_data(NEWS_CACHE_FILE) # <-- æ–°å¢é€™ä¸€è¡Œ

def validate_signature(request_body_bytes, signature_header):
    if not LINE_CHANNEL_SECRET: return True
    hash_obj = hmac.new(LINE_CHANNEL_SECRET.encode('utf-8'), request_body_bytes, hashlib.sha256)
    generated_signature = base64.b64encode(hash_obj.digest()).decode('utf-8')
    return hmac.compare_digest(generated_signature, signature_header)

def _utf16_len(s: str) -> int:
    # LINE ä»¥ UTF-16 code units è¨ˆæ•¸
    return len(s.encode('utf-16-le')) // 2

def _slice_by_utf16(s: str, max_units: int):
    # é€å­—ç´¯é€²ï¼Œç¢ºä¿ä¸æŠŠ surrogate pair åˆ‡æ–·
    buf, acc = [], 0
    for ch in s:
        u = _utf16_len(ch)
        if acc + u > max_units:
            yield ''.join(buf)
            buf, acc = [ch], u
        else:
            buf.append(ch); acc += u
    if buf: yield ''.join(buf)
    
def split_long_message(text, limit=None):
    if not text or not text.strip():
        return []
    # ä»¥ 5000 code units ç‚ºé è¨­ä¸Šé™ï¼ˆå®˜æ–¹æ–‡æª”ï¼‰
    # https://developers.line.biz/en/docs/partner-docs/development-guidelines/
    limit = limit or 5000

    if _utf16_len(text) <= limit:
        return [text.strip()]

    # å…ˆæŒ‰æ®µè½åˆ‡ï¼Œå†ç”¨ UTF-16 å®‰å…¨åˆ‡ç‰‡
    messages = []
    current = ""
    for para in text.split('\n'):
        if _utf16_len(current + para + '\n') <= limit:
            current += para + '\n'
        else:
            if current:
                messages.append(current.strip()); current = ""
            if _utf16_len(para) > limit:
                messages.extend(list(_slice_by_utf16(para, limit)))
            else:
                current = para + '\n'
    if current:
        messages.append(current.strip())

    if len(messages) > 1:
        messages = [f"({i+1}/{len(messages)})\n{m}" for i, m in enumerate(messages)]
    return messages

LAST_PUSH_TS = 0
MIN_PUSH_INTERVAL_SEC = float(os.getenv("LINE_MIN_PUSH_INTERVAL_SEC", "1.2"))  # è¦–æ–¹æ¡ˆå¾®èª¿

def _throttle():
    global LAST_PUSH_TS
    now = time.time()
    gap = now - LAST_PUSH_TS
    if gap < MIN_PUSH_INTERVAL_SEC:
        time.sleep(MIN_PUSH_INTERVAL_SEC - gap)
    LAST_PUSH_TS = time.time()

def send_line_messages(context_id, reply_token_or_none, text_messages_list):
    if not text_messages_list: return
    headers = {"Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}", "Content-Type": "application/json"}

    def _push_one(msg_text):
        _throttle()
        payload = {"to": context_id, "messages": [{"type": "text", "text": str(msg_text)}]}
        r = requests.post("https://api.line.me/v2/bot/message/push", headers=headers, json=payload, timeout=20)
        if r.status_code == 429:
            logging.warning("Push 429ï¼Œå°‡å»¶é²é‡è©¦ä¸€æ¬¡...")
            time.sleep(MIN_PUSH_INTERVAL_SEC * 2.5)
            _throttle()
            r = requests.post("https://api.line.me/v2/bot/message/push", headers=headers, json=payload, timeout=20)
        r.raise_for_status()

    # å…ˆå˜—è©¦ reply
    is_first_replied = False
    if reply_token_or_none:
        try:
            payload = {"replyToken": reply_token_or_none, "messages": [{"type": "text", "text": str(text_messages_list[0])}]}
            r = requests.post("https://api.line.me/v2/bot/message/reply", headers=headers, json=payload, timeout=20)
            r.raise_for_status()
            is_first_replied = True
        except requests.exceptions.RequestException as e:
            logging.error(f"Reply å¤±æ•—ï¼Œæ”¹ç”¨ Pushï¼š{e}")

    # å…¶é¤˜ç”¨ Push
    start = 1 if is_first_replied else 0
    for i in range(start, len(text_messages_list)):
        try:
            _push_one(text_messages_list[i])
        except requests.exceptions.RequestException as e:
            logging.error(f"Push å¤±æ•— part {i+1}ï¼š{e}")
            break
        
def get_user_profile(context_id, user_id):
    cache_key = (context_id, user_id)
    current_time = time.time()
    if cache_key in USER_PROFILE_CACHE and current_time - USER_PROFILE_CACHE[cache_key]['timestamp'] < USER_PROFILE_CACHE_SECONDS:
        return USER_PROFILE_CACHE[cache_key]['displayName']
    if context_id.startswith('G') or context_id.startswith('R'): url = f"https://api.line.me/v2/bot/group/{context_id}/member/{user_id}"
    elif context_id.startswith('U'): url = f"https://api.line.me/v2/bot/profile/{user_id}"
    else: return "æœªçŸ¥ç”¨æˆ¶"
    headers = {"Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        profile_data = response.json()
        display_name = profile_data.get("displayName", "ç„¡åæ°")
        USER_PROFILE_CACHE[cache_key] = {"displayName": display_name, "timestamp": current_time}
        logging.info(f"é€é API å–å¾—ç”¨æˆ¶ {user_id} çš„åç¨±: {display_name}ï¼Œä¸¦å·²æ›´æ–°å¿«å–ã€‚")
        return display_name
    except requests.exceptions.RequestException as e:
        logging.warning(f"ç„¡æ³•ç²å–ç”¨æˆ¶ {user_id} çš„å€‹äººè³‡æ–™: {e}")
        return "æŸä½æˆå“¡"

# ==============================================================================
# --- æ ¸å¿ƒæ¥­å‹™é‚è¼¯èˆ‡ Webhook äº‹ä»¶è™•ç† ---
# ==============================================================================
def generate_and_push_news_for_user(user_id, user_custom_keywords=None, is_immediate_push=False, reply_token=None):
    """
    *** å·²å‡ç´š v6ï¼šå¢åŠ äº†ä¸»é¡Œå›æº¯åŠŸèƒ½ï¼Œä¸¦ä¿æŒå¿«å–çµæ§‹ä¸è®Š ***
    """
    log_prefix = "å³æ™‚è«‹æ±‚" if is_immediate_push else "æ’ç¨‹æ¨æ’­"
    logging.info(f"[{log_prefix}] é–‹å§‹ç‚ºç”¨æˆ¶ {user_id} è™•ç†æ–°èè«‹æ±‚...")
    
    # *** ç¢ºå®šä¸»é¡Œåç¨±å’Œå¿«å–éµ ***
    theme_name = user_custom_keywords if user_custom_keywords else "é è¨­ AI ä¸»é¡Œ"
    cache_key = user_custom_keywords if user_custom_keywords else "__DEFAULT__"
    current_time = time.time()

    # --- æ­¥é©Ÿ 1: æª¢æŸ¥å¿«å– ---
    if cache_key in NEWS_CACHE:
        cached_item = NEWS_CACHE[cache_key]
        cache_age = current_time - cached_item.get("timestamp", 0)
        
        if cache_age < NEWS_SUMMARY_CACHE_SECONDS:
            logging.info(f"æ–°èå¿«å–å‘½ä¸­ï¼(é—œéµå­—: '{cache_key}', å¹´é½¡: {int(cache_age)}ç§’)")
            cached_reply_content = cached_item.get("reply_content")
            if cached_reply_content:
                # åœ¨å¿«å–å…§å®¹å‰ï¼ŒåŠ ä¸Šä¸»é¡Œå’Œ "å¾å¿«å–æä¾›" çš„æç¤º
                final_reply = f"é€™ä»½æ–°èæ‘˜è¦æ ¹æ“šã€Œ{theme_name}ã€ä¸»é¡Œç”¢ç”Ÿï¼ˆå¾å¿«å–æä¾›ğŸ˜Šï¼‰\n\n{cached_reply_content}"
                send_line_messages(user_id, reply_token, split_long_message(final_reply))
                return

    # --- æ­¥é©Ÿ 2: å¦‚æœå¿«å–æœªå‘½ä¸­ï¼ŒåŸ·è¡Œå®Œæ•´æµç¨‹ ---
    logging.info(f"æ–°èå¿«å–æœªå‘½ä¸­æˆ–å·²éæœŸ (é—œéµå­—: '{cache_key}')ï¼ŒåŸ·è¡Œå®Œæ•´æ–°èæ‘˜è¦æµç¨‹ã€‚")
    articles = fetch_and_parse_articles(custom_query=user_custom_keywords, limit=NEWS_FETCH_TARGET_COUNT)
    if not articles:
        send_line_messages(user_id, reply_token, [f"æŠ±æ­‰ï¼Œç›®å‰æœªèƒ½æ ¹æ“šæ‚¨çš„é—œéµå­—ã€Œ{theme_name}ã€æ‰¾åˆ°å¯æˆåŠŸæ“·å–çš„æ–°èã€‚"])
        return

    final_summary_raw = summarize_news_flow(articles)
    if not final_summary_raw or final_summary_raw.startswith("æŠ±æ­‰ï¼Œ"):
        send_line_messages(user_id, reply_token, [final_summary_raw or "æŠ±æ­‰ï¼Œä»Šæ—¥æ–°èæ‘˜è¦ç”Ÿæˆç•°å¸¸ï¼Œå…§å®¹ç‚ºç©ºã€‚"])
        return

    # --- æ­¥é©Ÿ 3: å° LLM åŸå§‹è¼¸å‡ºé€²è¡Œæ ¼å¼åŒ– ---
    # æ³¨æ„ï¼šæˆ‘å€‘ä¸å†å°‡ä¸»é¡Œæˆ–æ€è€ƒéç¨‹å­˜å…¥å¿«å–ï¼Œåªå­˜æœ€æ ¸å¿ƒçš„ã€å¸¶æ™‚é–“æˆ³è¨˜çš„æ­£å¼å›è¦†
    parsed_result = handle_llm_response_with_think(final_summary_raw)
    thinking_messages = parsed_result["thinking_messages"]
    formal_messages = parsed_result["formal_messages"]

    # æº–å‚™è¦ç™¼é€å’Œå„²å­˜çš„æ­£å¼å…§å®¹
    final_formal_reply_for_cache = ""
    if formal_messages:
        generation_time = datetime.fromtimestamp(current_time)
        time_str = generation_time.strftime("%Y-%m-%d %H:%M")
        full_formal_text = "\n".join(formal_messages)
        # é€™æ˜¯è¦å­˜å…¥å¿«å–çš„å…§å®¹ï¼ŒåªåŒ…å«æ™‚é–“æˆ³å’Œæ‘˜è¦
        final_formal_reply_for_cache = f"ç”¢ç”Ÿæ–¼ {time_str}\n\n{full_formal_text}"
    
    # --- æ­¥é©Ÿ 4: å„²å­˜æ–°çš„å¿«å– ---
    if final_formal_reply_for_cache:
        NEWS_CACHE[cache_key] = {
            "timestamp": current_time,
            "reply_content": final_formal_reply_for_cache # å„²å­˜ä¸å«ä¸»é¡Œçš„ã€å¸¶æ™‚é–“æˆ³è¨˜çš„å…§å®¹
        }
        save_json_data(NEWS_CACHE, NEWS_CACHE_FILE)
        logging.info(f"å·²æ›´æ–°æ–°èå¿«å– (é—œéµå­—: '{cache_key}')ã€‚")

    # --- æ­¥é©Ÿ 5: çµ„åˆæœ€çµ‚ç™¼é€çµ¦ç”¨æˆ¶çš„å®Œæ•´è¨Šæ¯ ---
    # åœ¨è¦ç™¼é€çš„å…§å®¹å‰ï¼Œæ‰åŠ ä¸Šä¸»é¡Œ
    final_reply_for_user = f"é€™ä»½æ–°èæ‘˜è¦æ ¹æ“šã€Œ{theme_name}ã€ä¸»é¡Œç”¢ç”Ÿ\n\n{final_formal_reply_for_cache}"
    
    messages_to_send = thinking_messages + split_long_message(final_reply_for_user)
    send_line_messages(user_id, reply_token, messages_to_send)
    
    logging.info(f"[{log_prefix}] å·²å®Œæˆå°ç”¨æˆ¶ {user_id} çš„æ–°èæ¨é€ã€‚")

def generate_news_for_single_user_job(user_id, keywords, remaining_users, is_immediate=False):
    with app.app_context():
        log_prefix = "èƒŒæ™¯å³æ™‚è«‹æ±‚" if is_immediate else "èƒŒæ™¯æ’ç¨‹æ¨æ’­"
        logging.info(f"[{log_prefix}] ä»»å‹™éˆå•Ÿå‹•ï¼Œç‚ºç”¨æˆ¶ {user_id} ç”¢ç”Ÿæ–°è...")
        try:
            generate_and_push_news_for_user(user_id=user_id, user_custom_keywords=keywords, is_immediate_push=is_immediate, reply_token=None)
        except Exception as e:
            logging.error(f"[{log_prefix}] èƒŒæ™¯ä»»å‹™ç‚ºç”¨æˆ¶ {user_id} ç”¢ç”Ÿæ–°èæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
        finally:
            if remaining_users:
                next_user_id, next_user_keywords = remaining_users[0]
                next_remaining_users = remaining_users[1:]
                run_time = datetime.now(scheduler.timezone) + timedelta(seconds=10)
                job_id = f"scheduled_chain_{next_user_id}_{int(run_time.timestamp())}"
                scheduler.add_job(generate_news_for_single_user_job, 'date', run_date=run_time, args=[next_user_id, next_user_keywords, next_remaining_users, False], id=job_id)
                logging.info(f"ä»»å‹™éˆï¼šç‚ºç”¨æˆ¶ {user_id} çš„ä»»å‹™å·²å®Œæˆï¼Œå·²è¨»å†Šä¸‹ä¸€å€‹ä»»å‹™çµ¦ {next_user_id}ã€‚")
            else:
                logging.info(f"ä»»å‹™éˆï¼šç‚ºç”¨æˆ¶ {user_id} çš„ä»»å‹™å·²å®Œæˆï¼Œä»»å‹™éˆçµæŸã€‚")

@app.route('/webhook', methods=['POST'])
def webhook():
    signature = request.headers.get("X-Line-Signature")
    body_bytes = request.get_data()
    if not validate_signature(body_bytes, signature):
        logging.error("Webhook: Invalid signature.")
        return jsonify({"status": "invalid signature"}), 400
    try:
        data = request.json
        for event in data.get("events", []):
            source, event_type, reply_token = event.get("source", {}), event.get("type"), event.get("replyToken")
            source_type = source.get("type")
            context_id = source.get(f'{source_type}Id') if source_type else None
            if not context_id: continue
            logging.info(f"æ”¶åˆ°äº‹ä»¶: type={event_type}, source_type={source_type}, context_id={context_id}")
            if event_type == "message" and event.get("message", {}).get("type") == "text":
                handle_text_message_event(context_id=context_id, user_id=source.get('userId'), reply_token=reply_token, user_text=event["message"]["text"])
            elif event_type == "follow":
                user_pref = USER_PREFERENCES.get(context_id, {})
                user_pref["subscribed_news"] = True
                USER_PREFERENCES[context_id] = user_pref
                save_json_data(USER_PREFERENCES, USER_PREFERENCES_FILE)
                send_line_messages(context_id, reply_token, ["æ„Ÿè¬æ‚¨åŠ æˆ‘å¥½å‹ï¼è¼¸å…¥ `/bot å¹«åŠ©` å¯ä»¥æŸ¥çœ‹æ‰€æœ‰æŒ‡ä»¤å–”ã€‚"])
            elif event_type == "unfollow" and context_id in USER_PREFERENCES:
                USER_PREFERENCES[context_id]["subscribed_news"] = False
                save_json_data(USER_PREFERENCES, USER_PREFERENCES_FILE)
        return jsonify({"status": "success"}), 200
    except Exception as e:
        logging.error(f"è™•ç† webhook æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

def handle_llm_response_with_think(llm_full_response):
    """
    è§£æå¸¶æœ‰ <think> çš„å›æ‡‰ï¼›è‹¥æ­£å¼å…§å®¹ç‚ºç©ºï¼Œä¸”é–‹å•Ÿå‚™æ´ï¼Œå‰‡ã€Œå…¨å–ã€ç›´æ¥å›å‚³å¯ç”¨å…§å®¹ã€‚
    """
    think_pattern = re.compile(r"<think>(.*?)</think>", re.DOTALL | re.IGNORECASE)

    result = {
        "thinking_messages": [],
        "formal_messages": []
    }

    show_thinking = os.getenv("SHOW_THINKING_PROCESS", "false").lower() == "true"
    fallback_on_empty = os.getenv("FALLBACK_ON_EMPTY", "true").lower() == "true"

    # å…ˆæŠ“ <think>
    match = think_pattern.search(llm_full_response or "")
    if match:
        thinking_text = (match.group(1) or "").strip()
        formal_text = (llm_full_response[match.end():] or "").strip()

        if thinking_text and show_thinking:
            result["thinking_messages"] = split_long_message(f"âš™ï¸ æˆ‘çš„æ€è€ƒéç¨‹ï¼š\n{thinking_text}")

        if formal_text:
            result["formal_messages"] = split_long_message(formal_text)
        else:
            # æ­£å¼å…§å®¹ç©º â†’ å•Ÿå‹•å‚™æ´
            if fallback_on_empty:
                # æ–¹æ¡ˆAï¼šç§»é™¤ <think> å¾Œçš„å®Œæ•´æ–‡æœ¬
                cleaned = think_pattern.sub("", llm_full_response or "").strip()
                if cleaned:
                    result["formal_messages"] = split_long_message(cleaned)
                else:
                    # æ–¹æ¡ˆBï¼šçœŸçš„éƒ½ç©ºï¼Œæœ€å¾Œå°±æŠŠåŸå­—ä¸²ç¡¬å¡ï¼ˆæ¥µç«¯ä¿éšªï¼‰
                    raw = (llm_full_response or "").strip()
                    if raw:
                        result["formal_messages"] = split_long_message(raw)
            # è‹¥æœªé–‹å•Ÿå‚™æ´ä¸”ç©ºï¼Œå°±ç¶­æŒç©ºï¼ˆç”±ä¸Šå±¤åˆ¤æ–·ï¼‰
    else:
        # æ²’æœ‰ <think>ï¼Œç›´æ¥ç•¶æ­£å¼å…§å®¹
        cleaned = (llm_full_response or "").strip()
        if cleaned:
            result["formal_messages"] = split_long_message(cleaned)
        elif fallback_on_empty:
            # ä»ç„¶ç©ºå°±åŸæ¨£å›å‚³ï¼ˆåŸºæœ¬ä¸æœƒç™¼ç”Ÿï¼Œä½†ä¿éšªï¼‰
            result["formal_messages"] = split_long_message(llm_full_response or "")

    return result

def handle_text_message_event(context_id, user_id, reply_token, user_text):
    """
    v6 ç‰ˆæœ¬ï¼Œä¿®æ­£äº†èŠå¤©æ¨¡å¼ä¸‹å° handle_llm_response_with_think çš„è™•ç† bugã€‚
    """
    # ... (è¨˜éŒ„æ­·å²çš„é‚è¼¯ä¿æŒä¸è®Š) ...
    display_name = get_user_profile(context_id, user_id)
    if context_id.startswith(('G', 'R')): formatted_message_content = f"{display_name}: {user_text}"
    else: formatted_message_content = user_text
    history = CONVERSATION_HISTORY.get(context_id, [])
    history.append({"role": "user", "content": formatted_message_content})
    if len(history) > MAX_HISTORY_MESSAGES: history = history[-MAX_HISTORY_MESSAGES:]
    CONVERSATION_HISTORY[context_id] = history
    save_json_data(CONVERSATION_HISTORY, CONVERSATION_HISTORY_FILE)
    logging.info(f"å·²è¨˜éŒ„è¨Šæ¯åˆ° {context_id}ã€‚ç•¶å‰æ­·å²é•·åº¦: {len(history)}")

    user_text_stripped = user_text.strip()
    if not user_text_stripped.startswith(BOT_TRIGGER_WORD): return

    command_text = user_text_stripped[len(BOT_TRIGGER_WORD):].strip()
    if not command_text or command_text.lower() in ["help", "å¹«åŠ©", "æŒ‡ä»¤"]:
        send_line_messages(context_id, reply_token, [HELP_MESSAGE.strip()]); return

    cmd_parts = command_text.lower().split()
    main_command = cmd_parts[0] if cmd_parts else ""

    # ... (æ–°èå’Œè¨‚é–±çš„ if/elif å€å¡Šä¿æŒä¸è®Š) ...
    if main_command in ["æ–°è", "news", "æ–°èæ‘˜è¦"]:
        # ... (æ­¤è™•é‚è¼¯ä¸è®Š)
        logging.info("åµæ¸¬åˆ°ã€Œæ–°èä¸€æ¬¡æ€§æŸ¥è©¢ã€æŒ‡ä»¤ (åŒæ­¥æ¨¡å¼)ã€‚")
        final_keywords = None; user_input_part = command_text[len(main_command):].strip()
        if user_input_part:
            if user_input_part.lower().startswith("é—œéµå­—:"): final_keywords = user_input_part[len("é—œéµå­—:"):].strip()
            else: final_keywords = user_input_part
        else:
            user_pref = USER_PREFERENCES.get(context_id, {});
            if user_pref.get("subscribed_news") and user_pref.get("news_keywords"): final_keywords = user_pref.get("news_keywords")
        if not final_keywords: final_keywords = None
        generate_and_push_news_for_user(user_id=context_id, user_custom_keywords=final_keywords, is_immediate_push=True, reply_token=reply_token)

    elif main_command == "è¨‚é–±":
        # ... (æ­¤è™•é‚è¼¯ä¸è®Š)
        logging.info("åµæ¸¬åˆ°ã€Œè¨‚é–±ã€æŒ‡ä»¤ã€‚")
        keywords_to_subscribe = command_text[len(main_command):].strip()
        user_pref = USER_PREFERENCES.get(context_id, {}); user_pref["subscribed_news"] = True; user_pref["news_keywords"] = keywords_to_subscribe or None
        reply_msg = f"âœ… è¨­å®šæˆåŠŸï¼å·²ç‚ºæ‚¨è¨‚é–±æ¯æ—¥æ–°èï¼Œä¸»é¡Œç‚ºï¼šã€Œ{keywords_to_subscribe or 'é è¨­ AI ä¸»é¡Œ'}ã€ã€‚"
        USER_PREFERENCES[context_id] = user_pref; save_json_data(USER_PREFERENCES, USER_PREFERENCES_FILE)
        send_line_messages(context_id, reply_token, [reply_msg])

    elif main_command == "æŸ¥çœ‹è¨‚é–±":
        # ... (æ­¤è™•é‚è¼¯ä¸è®Š)
        user_pref = USER_PREFERENCES.get(context_id, {}); reply_msg = "æ‚¨ç›®å‰å°šæœªè¨‚é–±æ¯æ—¥æ–°èå–”ã€‚"
        if user_pref.get("subscribed_news"): subscribed_keywords = user_pref.get("news_keywords", "é è¨­ AI ä¸»é¡Œ"); reply_msg = f"æ‚¨ç›®å‰çš„è¨‚é–±ç‹€æ…‹ç‚ºï¼š\n- ç‹€æ…‹ï¼šå·²è¨‚é–± âœ…\n- ä¸»é¡Œï¼šã€Œ{subscribed_keywords}ã€"
        send_line_messages(context_id, reply_token, [reply_msg])

    elif main_command == "å–æ¶ˆè¨‚é–±":
        # ... (æ­¤è™•é‚è¼¯ä¸è®Š)
        user_pref = USER_PREFERENCES.get(context_id, {}); user_pref["subscribed_news"] = False; USER_PREFERENCES[context_id] = user_pref
        save_json_data(USER_PREFERENCES, USER_PREFERENCES_FILE); send_line_messages(context_id, reply_token, ["â˜‘ï¸ å¥½çš„ï¼Œå·²ç‚ºæ‚¨å–æ¶ˆæ¯æ—¥æ–°èè¨‚é–±ã€‚"])
        
    # --- 3. ä¸€èˆ¬èŠå¤© (ä¿®æ­£å° handle_llm_response_with_think çš„è™•ç†) ---
    else:
        logging.info("ä½œç‚ºä¸€èˆ¬èŠå¤©å•é¡Œè™•ç†ã€‚")
        llm_response = generate_chat_response(context_id, command_text)
        
        # *** ä¿®æ”¹æ ¸å¿ƒ ***
        # 1. å…ˆå‘¼å« handle_llm_response_with_think ä¾†è§£æ LLM å›æ‡‰
        parsed_result = handle_llm_response_with_think(llm_response)
        
        # 2. å¾è¿”å›çš„å­—å…¸ä¸­å–å‡ºæ€è€ƒå’Œæ­£å¼è¨Šæ¯
        thinking_messages = parsed_result["thinking_messages"]
        formal_messages = parsed_result["formal_messages"]
        
        # 3. å°‡å®ƒå€‘åˆä½µæˆä¸€å€‹æœ€çµ‚è¦ç™¼é€çš„åˆ—è¡¨
        messages_to_send = thinking_messages + formal_messages
        
        # 4. ç™¼é€é€™å€‹åˆ—è¡¨
        send_line_messages(context_id, reply_token, messages_to_send)
        
        # 5. ç™¼é€æˆåŠŸå¾Œï¼Œæ‰æ›´æ–°æ­·å²ç´€éŒ„
        if not llm_response.startswith("æŠ±æ­‰ï¼Œ"):
            # æˆ‘å€‘åªå„²å­˜æ­£å¼å›è¦†çš„éƒ¨åˆ†åˆ°æ­·å²ç´€éŒ„
            # æ³¨æ„ï¼šé€™è£¡çš„ formal_messages æ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œæˆ‘å€‘éœ€è¦å°‡å®ƒåˆä½µå›å­—ä¸²
            cleaned_bot_response = "\n".join(formal_messages)
            
            history.append({"role": "assistant", "content": cleaned_bot_response})
            if len(history) > MAX_HISTORY_MESSAGES:
                history = history[-MAX_HISTORY_MESSAGES:]
            CONVERSATION_HISTORY[context_id] = history
            save_json_data(CONVERSATION_HISTORY, CONVERSATION_HISTORY_FILE)       

# ==============================================================================
# --- æ’ç¨‹èˆ‡æ‡‰ç”¨å•Ÿå‹• ---
# ==============================================================================
scheduler = BackgroundScheduler(timezone="Asia/Taipei", daemon=True)

def daily_news_push_job():
    with app.app_context():
        logging.info("APScheduler: ä»»å‹™éˆå•Ÿå‹•å™¨é–‹å§‹åŸ·è¡Œ...")
        users_to_push = [(uid, prefs.get("news_keywords")) for uid, prefs in load_json_data(USER_PREFERENCES_FILE).items() if prefs.get("subscribed_news")]
        if TARGET_USER_ID_FOR_TESTING and not any(u[0] == TARGET_USER_ID_FOR_TESTING for u in users_to_push):
            users_to_push.append((TARGET_USER_ID_FOR_TESTING, load_json_data(USER_PREFERENCES_FILE).get(TARGET_USER_ID_FOR_TESTING, {}).get("news_keywords")))
        if not users_to_push:
            logging.info("APScheduler: å•Ÿå‹•å™¨ç™¼ç¾æ²’æœ‰éœ€è¦è™•ç†çš„ç”¨æˆ¶ã€‚")
            return
        logging.info(f"APScheduler: å•Ÿå‹•å™¨æº–å‚™å•Ÿå‹•ä¸€å€‹åŒ…å« {len(users_to_push)} ä½ç”¨æˆ¶çš„ä»»å‹™éˆã€‚")
        first_user_id, first_user_keywords = users_to_push[0]
        remaining_users = users_to_push[1:]
        job_id = f"scheduled_chain_{first_user_id}_{int(time.time())}"
        scheduler.add_job(generate_news_for_single_user_job, 'date', run_date=datetime.now(scheduler.timezone) + timedelta(seconds=5), args=[first_user_id, first_user_keywords, remaining_users, False], id=job_id)
        logging.info(f"APScheduler: ä»»å‹™éˆçš„ç¬¬ä¸€å€‹ä»»å‹™å·²è¨»å†Šçµ¦ {first_user_id}ï¼Œå•Ÿå‹•å™¨ä»»å‹™çµæŸã€‚")

def shutdown_scheduler_on_exit():
    if scheduler.running: scheduler.shutdown(wait=False)

def _debug_test_call_openai_api():
    """
    æœ€å°åŒ–æ¸¬è©¦ï¼šç›´æ¥ç”¨ä½ ç¾æœ‰çš„ call_openai_api æ¸¬è©¦é€šè·¯ã€‚
    æœƒåˆ—å° base_urlã€modelã€å›æ‡‰é•·åº¦èˆ‡å‰ 300 å­—ï¼›è‹¥å¤±æ•—æœƒè¼¸å‡ºéŒ¯èª¤ç´°ç¯€ã€‚
    """
    try:
        base = os.getenv("OPENAI_BASE_URL", "https://api.openai.com")
        model = os.getenv("OPENAI_COMPLETION_MODEL", "gpt-4o-mini")
        key = os.getenv("OPENAI_API_KEY")

        print("[TEST] OPENAI_BASE_URL =", base)
        print("[TEST] OPENAI_COMPLETION_MODEL =", model)
        print("[TEST] OPENAI_API_KEY set? ", "YES" if key else "NO")

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ç°¡æ½”åŠ©ç†ï¼Œå›è¦†ä¸è¶…é20å­—ã€‚"},
            {"role": "user", "content": "å›è¦†ï¼šOK å³è¡¨ç¤ºAPIå¯ç”¨ã€‚"}
        ]
        out = call_openai_api(messages, model=model, max_tokens=1164, temperature=0.0)
        if out is None:
            print("[TEST] call_openai_api å›å‚³ None")
        else:
            print("[TEST] å›å‚³é•·åº¦ =", len(out))
            print("[TEST] å…§å®¹å‰1300å­—ï¼š", (out or "")[:1300])

        # é¡å¤–æª¢æŸ¥ï¼šç©ºå­—ä¸²æˆ–åƒ…ç©ºç™½
        if not out or not str(out).strip():
            print("[TEST][WARN] å›æ‡‰ç‚ºç©ºå­—ä¸²ï¼å¯èƒ½æ˜¯ proxy / base_url / body æ ¼å¼ / æ¨¡å‹åéŒ¯èª¤ã€‚")

    except Exception as e:
        print("[TEST][ERROR] ä¾‹å¤–ï¼š", repr(e))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Line Bot and News Fetcher")
    parser.add_argument('--test-news', action='store_true', help='Run in local test mode for news fetching and summarization.')
    parser.add_argument('--test-openai', action='store_true', help='Quickly test call_openai_api pipeline.')
    parser.add_argument('--keywords', type=str, default=None, help='Keywords for news fetching in test mode.')
    parser.add_argument('--limit', type=int, default=None, help='Number of articles to process in test mode.')
    args = parser.parse_args()

    if args.test_openai:
        _debug_test_call_openai_api()
        sys.exit(0)

    if args.test_news:
        def run_test_mode(keywords, limit):
            print("="*50 + "\nğŸš€ é€²å…¥æœ¬åœ°æ¸¬è©¦æ¨¡å¼ ğŸš€\n" + "="*50)
            articles = fetch_and_parse_articles(custom_query=keywords, limit=limit or NEWS_FETCH_TARGET_COUNT)
            if not articles:
                print("[!] æ¸¬è©¦ä¸­æ­¢ï¼šæœªèƒ½æˆåŠŸæ“·å–ä»»ä½•æ–°èå…§æ–‡ã€‚")
                return
            final_summary = summarize_news_flow(articles)
            print("\n" + "="*50 + "\nğŸ§ æœ€çµ‚ Podcast é¢¨æ ¼æ‘˜è¦ ğŸ§\n" + "="*50)
            print(final_summary)
            print("\n" + "="*50 + "\nâœ… æ¸¬è©¦æµç¨‹çµæŸ âœ…\n" + "="*50)
        run_test_mode(args.keywords, args.limit)
    else:
        logging.info("ğŸš€ å•Ÿå‹• Flask Web ä¼ºæœå™¨æ¨¡å¼ ğŸš€")
        required_env_vars = ['LINE_CHANNEL_ACCESS_TOKEN', 'LINE_CHANNEL_SECRET', 'OPENAI_API_KEY']
        if any(not os.getenv(var) for var in required_env_vars):
            logging.critical(f"CRITICAL: Missing required environment variables: {', '.join(v for v in required_env_vars if not os.getenv(v))}. Exiting.")
            exit(1)
        if not scheduler.get_jobs():
            scheduler.add_job(daily_news_push_job, 'cron', hour=9, minute=0, id='daily_news_cron_morning', replace_existing=True)
            scheduler.add_job(daily_news_push_job, 'cron', hour=16, minute=0, id='daily_news_cron_afternoon', replace_existing=True)
#             scheduler.add_job(daily_news_push_job, 'interval', minutes=960, id='news_interval_job', replace_existing=True)
            logging.info("å·²è¨­å®šæ¯æ—¥ 09:00 å’Œæ¯æ—¥ 16:00 çš„æ–°èæ¨æ’­æ’ç¨‹ã€‚")
            if os.getenv("RUN_JOB_ON_STARTUP", "False").lower() == "true":
                scheduler.add_job(daily_news_push_job, 'date', run_date=datetime.now(scheduler.timezone) + timedelta(seconds=15), id='startup_news_push')
                logging.info(f"å·²è¨­å®šåœ¨ 15 ç§’å¾ŒåŸ·è¡Œä¸€æ¬¡æ–°èæ¨æ’­ä»»å‹™ã€‚")
        if not scheduler.running:
            scheduler.start()
            logging.info("APScheduler started.")
            atexit.register(shutdown_scheduler_on_exit)
        port = int(os.environ.get("PORT", 5000))
        app.run(host='0.0.0.0', port=port, debug=False, use_reloader=False)
